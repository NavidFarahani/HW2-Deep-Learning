{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#In the name of God\n",
        "\n",
        "student_id = 401210923\n",
        "student_name = \"Navid Farahani\"\n",
        "\n",
        "print(\"your student id:\", student_id)\n",
        "print(\"your name:\", student_name)\n",
        "\n",
        "print(\" For better understanding the Forward-Forward algorithm, I used watched this video : https://www.youtube.com/watch?v=kvdOow3__CI\")\n",
        "print(\" For explaining the codes, I wrote comment for them.\")\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch.optim import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcDvUA7b6PSG",
        "outputId": "d2b64eff-7cc7-44d2-f8f8-c6b5b1345e27"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "your student id: 401210923\n",
            "your name: Navid Farahani\n",
            " For better understanding the Forward-Forward algorithm, I used watched this video : https://www.youtube.com/watch?v=kvdOow3__CI\n",
            " For explaining the codes, I wrote comment for them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Part A\n",
        "# Selecting the device:\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device=torch.device(\"cuda\")\n",
        "else:\n",
        "    device=torch.device(\"cpu\")\n",
        "\n",
        "# choosing number of images, number of test images are considered 1/5 of train's\n",
        "\n",
        "num_train=50000\n",
        "num_test=num_train//5\n",
        "\n",
        "# If the device is GPU, we determine num_workers\n",
        "if torch.cuda.is_available():\n",
        "    cuda_kwargs = {\"num_workers\": 3, \"pin_memory\": True, \"shuffle\": True}\n",
        "    # train_kwargs.update(cuda_kwargs)\n",
        "    # test_kwargs.update(cuda_kwargs)\n",
        "\n",
        "# we use pytorch for MNISt data, so we can apply a transform to images for normaliaztion with zero mean and unit std.\n",
        "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0,),(1,)),])\n",
        "\n",
        "#determining test and train images\n",
        "\n",
        "trainset = MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(trainset, batch_size=num_train, shuffle=True)\n",
        "\n",
        "\n",
        "testset = MNIST('~/.pytorch/MNIST_data/',download=True, train=False, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(testset, batch_size=num_test,shuffle=False)\n",
        "\n",
        "# taking variables to device and vectorizing the images.\n",
        "x,y=next(iter(train_loader))\n",
        "x,y=x.to(device),y.to(device)\n",
        "x=torch.reshape(x,(num_train,x.shape[2]*x.shape[3]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "swxv0E6v6kOU",
        "outputId": "00f5d4ee-cb53-4adb-b123-b2ee1a087fdf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 93963204.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 58042977.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 36659518.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2323518.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.pytorch/MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.pytorch/MNIST_data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Part B\n",
        "\n",
        "# according to the article, we need to put the one-hot labels on the images for classification\n",
        "# so we wrote combined_image function\n",
        "def combined_image(x, y):\n",
        "    x_and_y=x.clone()\n",
        "    x_and_y[:,:10]=0.0\n",
        "    xlabels=range(x.shape[0])\n",
        "    x_and_y[xlabels,y]=1\n",
        "    return x_and_y\n",
        "\n",
        "# we have a one-hot vector for every images, so for negative images we need to shuffle that vector.\n",
        "# so we wrote shuffled_y function\n",
        "\n",
        "def shuffled_y(y):\n",
        "    y=y.to('cpu')\n",
        "    y=y.numpy()\n",
        "    y_shuffled=np.zeros(y.shape,np.uint8)\n",
        "    for i in range(np.shape(y)[0]):\n",
        "        y_shuffled[i]=np.random.randint(10)\n",
        "        while(y_shuffled[i]==y[i]):\n",
        "            y_shuffled[i]=np.random.randint(10)\n",
        "    y_shuffled=torch.from_numpy(y_shuffled)\n",
        "    return y_shuffled.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# positive data is combining labels and the images\n",
        "x_positive = combined_image(x, y)\n",
        "\n",
        "# negative data is combining shuffled labels and the images.\n",
        "y_negative = shuffled_y(y)\n",
        "y3=torch.zeros_like(y)\n",
        "y3[:]=y_negative[:]\n",
        "x_negative = combined_image(x, y3)\n",
        "\n",
        "\n",
        "# for better understanding, I plot an image fo positive and negative images.\n",
        "\n",
        "index_for_img=np.random.randint(num_train)\n",
        "plt.subplot(1,2,1)\n",
        "the_img_pos=torch.reshape(x_positive[index_for_img,:],(28,28))\n",
        "the_img_pos=the_img_pos.to('cpu')\n",
        "the_img_numpy_pos=the_img_pos.numpy()\n",
        "plt.imshow(np.array(255*the_img_numpy_pos,dtype=np.uint8),cmap='gray')\n",
        "plt.title(\"Positive Data\")\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "the_img_neg=torch.reshape(x_negative[index_for_img,:],(28,28))\n",
        "the_img_neg=the_img_neg.to('cpu')\n",
        "the_img_numpy_neg=the_img_neg.numpy()\n",
        "plt.imshow(np.array(255*the_img_numpy_neg,dtype=np.uint8),cmap='gray')\n",
        "plt.title(\"Negative Data\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "2pXkvjX36nBP",
        "outputId": "a0c88a18-c462-4f7e-ac84-0c7f62d98ff3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Negative Data')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAEjCAYAAACSDWOaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqOElEQVR4nO3deXxU5b3H8e8QYBJJmJiFhEACYbEoKPZGgYgsKhKocmVfigoiixrwBYjeploWLcblFkSKWKiGvWBY5Eq9UEHBBUIF5FIvlQuWJSwJaxLWAMlz/6BMMyYkGTI5M5N83q/X83ox5zlzzjMH5stvzpznjM0YYwQAAGCRGt4eAAAAqF4oPgAAgKUoPgAAgKUoPgAAgKUoPgAAgKUoPgAAgKUoPgAAgKUoPgAAgKUoPgAAgKUoPqopm82myZMnl2vdxo0ba+jQoZU6HgBV3+TJk2Wz2bw9DPgAig8fMG/ePNlsNmcLDAzUbbfdptGjRys7O9uSMWzevFmTJ09WTk6OJfsrj8aNGzuPSY0aNRQaGqo777xTI0eO1NatWyu07ddff10ff/yxZwYKVLLrGREYGKgjR44U6+/cubNatWrlhZEVd+HCBU2ePFkbN2709lCcrhc919stt9yiuLg49ejRQ2lpacrPz7/pbX/66afl/iCHf6H48CGvvvqqFi5cqN///ve67777NHv2bCUmJurChQse39fFixf1yiuvOB9v3rxZU6ZMKbH42LNnj+bOnevxMZTH3XffrYULF2rBggVKTU3VAw88oE8++UTt2rXT+PHjb3q7FB/wR/n5+XrjjTe8PYxSXbhwQVOmTCmx+HjllVd08eJF6wf1T7Nnz9bChQs1c+ZMDR8+XKdPn9awYcPUpk0bZWZm3tQ2P/30U02ZMsXDI636anp7APiX7t2765577pEkDR8+XOHh4Zo2bZpWr16tQYMGeXRfgYGB5V7Xbrd7dN/uaNCggR5//HGXZW+++aZ++ctfavr06WrevLmeffZZL40OsNbdd9+tuXPnKiUlRTExMd4ejttq1qypmjW9999O3759FRER4Xw8ceJELV68WE8++aT69eunjIwMr42tuuHMhw978MEHJUn79++XJF29elWvvfaamjZtKrvdrsaNG+vXv/51sVOG27ZtU1JSkiIiIhQUFKT4+HgNGzbMZZ2i13xMnjxZL774oiQpPj7eeWrywIEDklyv+di2bZtsNpvmz59fbLzr1q2TzWbTmjVrnMuOHDmiYcOGKSoqSna7XS1bttSHH35YoeMSFBSkhQsXKiwsTFOnTlXRH2b+z//8T913330KDw9XUFCQEhIStHz58mKv/fz585o/f77ztV5/fQcPHtRzzz2nn/3sZwoKClJ4eLj69evnPBaAN/36179WQUFBuc9+LFq0SAkJCQoKClJYWJgGDhxY4if8WbNmqUmTJgoKClKbNm301VdfqXPnzurcubNzncuXL2vixIlKSEiQw+FQnTp11KFDB33xxRfOdQ4cOKDIyEhJ0pQpU5zvr6JZU/Saj1atWumBBx4oNp7CwkI1aNBAffv2dVn2zjvvqGXLlgoMDFRUVJRGjRqlM2fOlOtY3MjgwYM1fPhwbd26VZ999plz+VdffaV+/fopLi5OdrtdsbGxGjdunMuZm6FDh2rWrFmS5PK1znXlyaPqiuLDh/3444+SpPDwcEnXzoZMnDhR//Zv/6bp06erU6dOSk1N1cCBA53POX78uLp27aoDBw7oV7/6lWbOnKnBgweXWtH37t3beWZl+vTpWrhwoRYuXOgMkaLuueceNWnSRB999FGxvmXLlunWW29VUlKSJCk7O1vt2rXT+vXrNXr0aM2YMUPNmjXT008/rXfeeeemj4skBQcHq1evXjpy5Ih2797tXD5jxgz9/Oc/16uvvqrXX39dNWvWVL9+/fTnP//Zuc7ChQtlt9vVoUMH52sdNWqUJOnbb7/V5s2bNXDgQL377rt65plntGHDBnXu3LlSvv4C3BEfH68nn3xSc+fO1dGjR0tdd+rUqXryySfVvHlzTZs2TWPHjtWGDRvUsWNHl69XZ8+erdGjR6thw4Z666231KFDB/Xs2VOHDx922V5eXp7++Mc/qnPnznrzzTc1efJknThxQklJSdq5c6ckKTIyUrNnz5Yk9erVy/n+6t27d4ljHDBggL788ktlZWW5LP/666919OhRl2wbNWqUXnzxRbVv314zZszQU089pcWLFyspKUlXrlwp7yEs0RNPPCFJ+stf/uJclp6ergsXLujZZ5/VzJkzlZSUpJkzZ+rJJ590GdPDDz8sSc7XunDhQmd/efKo2jLwurS0NCPJrF+/3pw4ccJkZmaapUuXmvDwcBMUFGQOHz5sdu7caSSZ4cOHuzx3woQJRpL5/PPPjTHGrFq1ykgy3377ban7lGQmTZrkfPz2228bSWb//v3F1m3UqJEZMmSI83FKSoqpVauWOX36tHNZfn6+CQ0NNcOGDXMue/rpp039+vXNyZMnXbY3cOBA43A4zIULF0odY6NGjcwjjzxyw/7p06cbSWb16tXOZT/d5uXLl02rVq3Mgw8+6LK8Tp06Lq/pRs83xpgtW7YYSWbBggWljheoLNcz4ttvvzU//vijqVmzpnn++eed/Z06dTItW7Z0Pj5w4IAJCAgwU6dOddnO3/72N1OzZk3n8vz8fBMeHm7uvfdec+XKFed68+bNM5JMp06dnMuuXr1q8vPzXbZ35swZExUV5fK+P3HiRLF8uW7SpEmm6H87e/bsMZLMzJkzXdZ77rnnTHBwsPP9+NVXXxlJZvHixS7rrV27tsTlN9rviRMnSuw/c+aMkWR69erlXFZSFqSmphqbzWYOHjzoXJacnGxu9F9pefOoOuLMhw/p0qWLIiMjFRsbq4EDByo4OFirVq1SgwYN9Omnn0pSsYssX3jhBUlyVtKhoaGSpDVr1lT408CNDBgwQFeuXNHKlSudy/7yl78oJydHAwYMkCQZY7RixQr16NFDxhidPHnS2ZKSkpSbm6sdO3ZUaBzBwcGSpLNnzzqXBQUFOf985swZ5ebmqkOHDuXeV9HnX7lyRadOnVKzZs0UGhpa4fECntCkSRM98cQTmjNnjo4dO1biOitXrlRhYaH69+/v8t6Ljo5W8+bNnV+VbNu2TadOndKIESNcrsUYPHiwbr31VpdtBgQEqHbt2pKufQVy+vRpXb16Vffcc89Nvzduu+023X333Vq2bJlzWUFBgZYvX64ePXo434/p6elyOBx6+OGHXV5PQkKCgoODXb76uRllZcn58+d18uRJ3XfffTLG6LvvvivXdiuaR1UZxYcPmTVrlj777DN98cUX2r17t/7xj384v8I4ePCgatSooWbNmrk8Jzo6WqGhoTp48KAkqVOnTurTp4+mTJmiiIgIPfbYYxWeSvZTrVu3VosWLVwCY9myZYqIiHBep3LixAnl5ORozpw5ioyMdGlPPfWUpGtfEVXEuXPnJEkhISHOZWvWrFG7du0UGBiosLAw52ng3Nzccm3z4sWLmjhxomJjY2W32xUREaHIyEjl5OSUextAZXvllVd09erVG177sXfvXhlj1Lx582Lvv7///e/O99713PhprtSsWVONGzcutt358+frrrvuUmBgoMLDwxUZGak///nPFXpvDBgwQN98841zCvHGjRt1/Phx5weZ668nNzdX9erVK/Z6zp07VylZcujQIQ0dOlRhYWEKDg5WZGSkOnXqJEnlfr0VzaOqjNkuPqRNmzbO2S43UtYNemw2m5YvX66MjAx98sknWrdunYYNG6bf/e53ysjIcFb4FTVgwABNnTpVJ0+eVEhIiP7rv/5LgwYNcn56KiwslCQ9/vjjGjJkSInbuOuuuyo0hu+//17Sv4Lzq6++0r//+7+rY8eOeu+991S/fn3VqlVLaWlpWrJkSbm2OWbMGKWlpWns2LFKTEyUw+GQzWbTwIEDna8J8LYmTZro8ccf15w5c/SrX/2qWH9hYaFsNpv++7//WwEBAcX6byYHFi1apKFDh6pnz5568cUXVa9ePQUEBCg1NdV5fdrNGDBggFJSUpSenq6xY8fqo48+ksPhULdu3VxeT7169bR48eISt1HS9Wnu+GmWFBQU6OGHH9bp06f1H//xH2rRooXq1KmjI0eOaOjQoeXKAk/kUVVG8eEnGjVqpMLCQu3du1e33367c3l2drZycnLUqFEjl/XbtWundu3aaerUqVqyZIkGDx6spUuXavjw4SVu3927Dg4YMEBTpkzRihUrFBUVpby8PJeLwyIjIxUSEqKCggJ16dLFrW2Xx7lz57Rq1SrFxsY6j8eKFSsUGBiodevWuUwPTktLK/b8G73e5cuXa8iQIfrd737nXHbp0iWfuvkaIF07+7Fo0SK9+eabxfqaNm0qY4zi4+N122233XAb13Nj3759LrNOrl69qgMHDrh8QFi+fLmaNGmilStXurx/Jk2a5LJNd7MkPj5ebdq00bJlyzR69GitXLlSPXv2dHkPN23aVOvXr1f79u1dvsrwlOsXiV4/0/y3v/1N//d//6f58+e7XGBadDbMdTd6ve7kUXXE1y5+4he/+IUkFZslMm3aNEnSI488Iuna94qmyNRT6dq9ASSV+tVLnTp1JKnc/8nefvvtuvPOO7Vs2TItW7ZM9evXV8eOHZ39AQEB6tOnj1asWOH8VFHUiRMnyrWfkly8eFFPPPGETp8+rZdfftn55g8ICJDNZlNBQYFz3QMHDpR4M7E6deqU+FoDAgKKHb+ZM2e6bBPwBU2bNtXjjz+uP/zhD8Vmi/Tu3VsBAQGaMmVKsX/PxhidOnVK0rXZa+Hh4Zo7d66uXr3qXGfx4sXFprBeP4NSdHtbt27Vli1bXNa75ZZbJJU/S6RrH2YyMjL04Ycf6uTJky5fuUhS//79VVBQoNdee63Yc69evVqhDwdLlizRH//4RyUmJuqhhx6SVPJrNcZoxowZxZ5/o+x0J4+qI858+InWrVtryJAhmjNnjnJyctSpUyf99a9/1fz589WzZ0/np5b58+frvffeU69evdS0aVOdPXtWc+fOVd26dZ0FTEkSEhIkSS+//LIGDhyoWrVqqUePHs43VkkGDBigiRMnKjAwUE8//bRq1HCtZd944w198cUXatu2rUaMGKE77rhDp0+f1o4dO7R+/XqdPn26zNd95MgRLVq0SNK1sx27d+9Wenq6srKy9MILLzinyErXCrBp06apW7du+uUvf6njx49r1qxZatasmXbt2lXs9a5fv17Tpk1TTEyM4uPj1bZtWz366KNauHChHA6H7rjjDm3ZskXr1693TncGfMnLL7+shQsXas+ePWrZsqVzedOmTfXb3/5WKSkpOnDggHr27KmQkBDt379fq1at0siRIzVhwgTVrl1bkydP1pgxY/Tggw+qf//+OnDggObNm6emTZu6fKp/9NFHtXLlSvXq1UuPPPKI9u/fr/fff1933HGH85oJ6dpFlnfccYeWLVum2267TWFhYWrVqlWpt3/v37+/JkyYoAkTJigsLKzY2dJOnTpp1KhRSk1N1c6dO9W1a1fVqlVLe/fuVXp6umbMmOFyT5AbWb58uYKDg3X58mUdOXJE69at0zfffKPWrVsrPT3duV6LFi3UtGlTTZgwQUeOHFHdunW1YsWKEu8pcj07n3/+eSUlJSkgIEADBw50K4+qJe9MskFRRafRlebKlStmypQpJj4+3tSqVcvExsaalJQUc+nSJec6O3bsMIMGDTJxcXHGbrebevXqmUcffdRs27bNZVsqYSrca6+9Zho0aGBq1KjhMu32p1Ntr9u7d6+RZCSZr7/+usQxZ2dnm+TkZBMbG2tq1aploqOjzUMPPWTmzJlT5nFp1KiRc/s2m83UrVvXtGzZ0owYMcJs3bq1xOd88MEHpnnz5sZut5sWLVqYtLS0YtP7jDHmhx9+MB07djRBQUFGkvP1nTlzxjz11FMmIiLCBAcHm6SkJPPDDz/c8BgAVigtI4YMGWIkuUy1vW7FihXm/vvvN3Xq1DF16tQxLVq0MMnJyWbPnj0u67377rumUaNGxm63mzZt2phvvvnGJCQkmG7dujnXKSwsNK+//rpzvZ///OdmzZo1ZsiQIaZRo0Yu29u8ebNJSEgwtWvXdsmakt6L17Vv377E2wkUNWfOHJOQkGCCgoJMSEiIufPOO81LL71kjh49esPnFN3v9RYYGGgaNmxoHn30UfPhhx+6ZOh1u3fvNl26dDHBwcEmIiLCjBgxwvzP//yPkWTS0tKc6129etWMGTPGREZGGpvN5vL6yptH1ZHNmJ+ckwMAVGuFhYWKjIxU7969vfa7TqjauOYDAKqxS5cuFbsuZMGCBTp9+rTL7dUBT+LMBwBUYxs3btS4cePUr18/hYeHa8eOHfrggw90++23a/v27c4biwGexAWnAFCNNW7cWLGxsXr33Xd1+vRphYWF6cknn9Qbb7xB4YFKw5kPAABgKa75AAAAlqL4AAAAlvK5az4KCwt19OhRhYSEuH2bXgCeYYzR2bNnFRMTU+zmcb6K7AC8y63cqKwbiPz+9793uWnNjW4K9VOZmZkuN4Oh0Wjea5mZmZUVESW62dwwhuyg0XyllSc3KqX4WLp0qaldu7b58MMPzf/+7/+aESNGmNDQUJOdnV3mc3Nycir9wOTm5pbavP0XR6P5SsvJyamMiChRRXLDmH9lR2ZmJu9tGs2LrTy5USnFR5s2bUxycrLzcUFBgYmJiTGpqallPteKgCiLt//iaDRfabm5uRXKAndUJDeM+Vd2lDZmbx9PGq06tPLkhse/zL18+bK2b9/u8sNANWrUUJcuXYr9+qF07ZdW8/LyXBqA6sXd3JDIDsCfebz4OHnypAoKChQVFeWyPCoqqtjPPktSamqqHA6Hs8XGxnp6SAB8nLu5IZEdgD/z+mXsKSkpys3NdbbMzExvDwmAHyA7AP/l8am2ERERCggIUHZ2tsvy7OxsRUdHF1vfbrfLbrd7ehgA/Ii7uSGRHYA/8/iZj9q1ayshIUEbNmxwLissLNSGDRuUmJjo6d3dFJvNVmoDYC1P5obD4eC9Dfi6cl1G7qalS5cau91u5s2bZ3bv3m1GjhxpQkNDTVZWVpnPZTocjeY7zcrZLhXJDWPIDhrNV1p5cqNS7nA6YMAAnThxQhMnTlRWVpbuvvturV27ttjFZABwHbkBVB8+96u2eXl5cjgc3h4GAEm5ubmqW7eut4dRLmQH4BvKkxten+0CAACqF4oPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgqZreHgBuTmxsbKn9ffv2LbU/MTGx1P527dpVaP/Tpk0rtT89Pb3U/oyMjFL7AdwcsgO+wONnPiZPniybzebSWrRo4endAKhCyA2geqmUMx8tW7bU+vXr/7WTmpxgAVA6cgOoPirl3V2zZk1FR0dXxqYBVFHkBlB9VMoFp3v37lVMTIyaNGmiwYMH69ChQzdcNz8/X3l5eS4NQPXjTm5IZAfgzzxefLRt21bz5s3T2rVrNXv2bO3fv18dOnTQ2bNnS1w/NTVVDofD2cq6GAlA1eNubkhkB+DPPF58dO/eXf369dNdd92lpKQkffrpp8rJydFHH31U4vopKSnKzc11tszMTE8PCYCPczc3JLID8GeVfkVXaGiobrvtNu3bt6/EfrvdLrvdXtnDAOBHysoNiewA/JnNGGMqcwfnzp1TXFycJk+erOeff77M9fPy8uRwOCpzSFXC5s2bS+0vay6+rytrLv8LL7xQaj+fgj0jNzdXdevWtXy/7uaGRHaUF9lBdlS28uSGx792mTBhgjZt2qQDBw5o8+bN6tWrlwICAjRo0CBP7wpAFUFuANWLx792OXz4sAYNGqRTp04pMjJS999/vzIyMhQZGenpXQGoIsgNoHrxePGxdOlST28SQBVHbgDVCz8sBwAALEXxAQAALEXxAQAALEXxAQAALMXPRvqo/v37l9pf0bn4FZ3LXtZc+q1bt5baP3bs2FL7+/Xr5+6QXJR1/ICqiuwgO/wBZz4AAIClKD4AAIClKD4AAIClKD4AAIClKD4AAIClKD4AAIClKD4AAIClKD4AAICluMmYjzp06FCFnl/WjXx8/UY6Zd0IqV27dhaNBPAvZAfZ4Q848wEAACxF8QEAACxF8QEAACxF8QEAACxF8QEAACxF8QEAACxF8QEAACzFfT58VEZGRqn9cXFxpfY3aNDAk8PxObGxsd4eAuCTyI7SkR2+gTMfAADAUhQfAADAUhQfAADAUhQfAADAUhQfAADAUhQfAADAUhQfAADAUm7f5+PLL7/U22+/re3bt+vYsWNatWqVevbs6ew3xmjSpEmaO3eucnJy1L59e82ePVvNmzf35LirvczMzAr1e1tF7yWwZcsWD40EViA3fAfZQXb4ArfPfJw/f16tW7fWrFmzSux/66239O677+r999/X1q1bVadOHSUlJenSpUsVHiwA/0RuACjK7TMf3bt3V/fu3UvsM8bonXfe0SuvvKLHHntMkrRgwQJFRUXp448/1sCBAys2WgB+idwAUJRHr/nYv3+/srKy1KVLF+cyh8Ohtm3b3vBUV35+vvLy8lwagOrjZnJDIjsAf+bR4iMrK0uSFBUV5bI8KirK2fdTqampcjgczsZ994Hq5WZyQyI7AH/m9dkuKSkpys3NdTZfv9gJgG8gOwD/5dHiIzo6WpKUnZ3tsjw7O9vZ91N2u11169Z1aQCqj5vJDYnsAPyZR4uP+Ph4RUdHa8OGDc5leXl52rp1qxITEz25KwBVBLkBVD9uz3Y5d+6c9u3b53y8f/9+7dy5U2FhYYqLi9PYsWP129/+Vs2bN1d8fLx+85vfKCYmxmVOP6q+sr5/HzduXIW2f/jw4Qo9H9YiN1BeZEf14HbxsW3bNj3wwAPOx+PHj5ckDRkyRPPmzdNLL72k8+fPa+TIkcrJydH999+vtWvXKjAw0HOjBuBXyA0ARbldfHTu3FnGmBv222w2vfrqq3r11VcrNDAAVQe5AaAor892AQAA1QvFBwAAsBTFBwAAsBTFBwAAsBTFBwAAsJTbs11QPZQ1175v376l9pc1F7+s7Zd1q+wXXnih1H4A3kF2oDw48wEAACxF8QEAACxF8QEAACxF8QEAACxF8QEAACxF8QEAACxF8QEAACzFfT78VFlz4RMTE0vt79evnyeH47ay5uK3b9++Qs8HUDKyg+zwBZz5AAAAlqL4AAAAlqL4AAAAlqL4AAAAlqL4AAAAlqL4AAAAlqL4AAAAluI+H37K1+filyU2NrbU/m+++abU/gkTJpTa/9FHH7k9JqA6IDvIDl/AmQ8AAGApig8AAGApig8AAGApig8AAGApig8AAGApig8AAGApig8AAGAp7vPhp/r37+/tIZSqrLn4ffv2LbV/3LhxpfYvW7bM7TEVxVx+VFdkB9nhC9w+8/Hll1+qR48eiomJkc1m08cff+zSP3ToUNlsNpfWrVs3T40XgB8iNwAU5Xbxcf78ebVu3VqzZs264TrdunXTsWPHnO1Pf/pThQYJwL+RGwCKcvtrl+7du6t79+6lrmO32xUdHX3TgwJQtZAbAIqqlAtON27cqHr16ulnP/uZnn32WZ06deqG6+bn5ysvL8+lAah+3MkNiewA/JnHi49u3bppwYIF2rBhg958801t2rRJ3bt3V0FBQYnrp6amyuFwOFtZFxsBqHrczQ2J7AD8mcdnuwwcOND55zvvvFN33XWXmjZtqo0bN+qhhx4qtn5KSorGjx/vfJyXl0eIANWMu7khkR2AP6v0+3w0adJEERER2rdvX4n9drtddevWdWkAqreyckMiOwB/Vun3+Th8+LBOnTql+vXrV/au4EMyMzNL7Z8+fXqp/cuXLy+1/5tvvim1v6y5/A0aNCi1v6zxoXKRG9UX2VE9uF18nDt3zuXTyP79+7Vz506FhYUpLCxMU6ZMUZ8+fRQdHa0ff/xRL730kpo1a6akpCSPDhyA/yA3ABTldvGxbds2PfDAA87H179zHTJkiGbPnq1du3Zp/vz5ysnJUUxMjLp27arXXntNdrvdc6MG4FfIDQBFuV18dO7cWcaYG/avW7euQgMCUPWQGwCK4oflAACApSg+AACApSg+AACApSg+AACApWymtKvAvCAvL08Oh8Pbw4CPa9euXan9W7ZsKbW/rHsJxMXFuT2mqig3N9dvbt5FdqA8yI7KV57c4MwHAACwFMUHAACwFMUHAACwFMUHAACwFMUHAACwFMUHAACwFMUHAACwFPf5QJVU0X/WNpvNQyPxb9znA9UN2VFx3OcDAAD4HIoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgKYoPAABgqZreHgBwM2JjY726/czMzErdP4DKQXb4Bs58AAAAS1F8AAAAS1F8AAAAS1F8AAAAS1F8AAAAS1F8AAAAS1F8AAAAS3GfD/ilsWPHVuj56enppfYzFx+omsgO3+DWmY/U1FTde++9CgkJUb169dSzZ0/t2bPHZZ1Lly4pOTlZ4eHhCg4OVp8+fZSdne3RQQPwL2QHgKLcKj42bdqk5ORkZWRk6LPPPtOVK1fUtWtXnT9/3rnOuHHj9Mknnyg9PV2bNm3S0aNH1bt3b48PHID/IDsAFOXW1y5r1651eTxv3jzVq1dP27dvV8eOHZWbm6sPPvhAS5Ys0YMPPihJSktL0+23366MjAy1a9fOcyMH4DfIDgBFVeiC09zcXElSWFiYJGn79u26cuWKunTp4lynRYsWiouL05YtW0rcRn5+vvLy8lwagKqN7ACqt5suPgoLCzV27Fi1b99erVq1kiRlZWWpdu3aCg0NdVk3KipKWVlZJW4nNTVVDofD2Sr7R38AeBfZAeCmi4/k5GR9//33Wrp0aYUGkJKSotzcXGfjSmGgaiM7ANzUVNvRo0drzZo1+vLLL9WwYUPn8ujoaF2+fFk5OTkun2Cys7MVHR1d4rbsdrvsdvvNDAOAnyE7AEhuFh/GGI0ZM0arVq3Sxo0bFR8f79KfkJCgWrVqacOGDerTp48kac+ePTp06JASExM9N2pUeePGjSu1f/z48RXa/o2uI0DlIDtgFbLDP7hVfCQnJ2vJkiVavXq1QkJCnN/FOhwOBQUFyeFw6Omnn9b48eMVFhamunXrasyYMUpMTORqdaAaIzsAFOVW8TF79mxJUufOnV2Wp6WlaejQoZKk6dOnq0aNGurTp4/y8/OVlJSk9957zyODBeCfyA4ARbn9tUtZAgMDNWvWLM2aNeumBwWgaiE7ABTFD8sBAABLUXwAAABLUXwAAABLUXwAAABLUXwAAABL3dQdTlEx5fkNCn+/VXRZr3Hs2LGl9vfr169C+09PTy+1f/r06RXaPuANZAfZUVVw5gMAAFiK4gMAAFiK4gMAAFiK4gMAAFiK4gMAAFiK4gMAAFiK4gMAAFiK+3z4qHbt2lXo+YmJiRXqb9iwYYX6y3M/goooay5+//79K3X/gK8iO0pHdvgGznwAAABLUXwAAABLUXwAAABLUXwAAABLUXwAAABLUXwAAABLUXwAAABLcZ8PL8jMzKzwOhWdC1/WXPuy5vKXpazxZ2RklNo/bdq0Cj0fqIrIDrKjquDMBwAAsBTFBwAAsBTFBwAAsBTFBwAAsBTFBwAAsBTFBwAAsBTFBwAAsJZxw+uvv27uueceExwcbCIjI81jjz1mfvjhB5d1OnXqZCS5tFGjRpV7H7m5ucWeT6PRvNNyc3PdiQiyg0ajlSs33DrzsWnTJiUnJysjI0OfffaZrly5oq5du+r8+fMu640YMULHjh1ztrfeesud3QCoYsgOAEW5dYfTtWvXujyeN2+e6tWrp+3bt6tjx47O5bfccouio6M9M0IAfo/sAFBUha75yM3NlSSFhYW5LF+8eLEiIiLUqlUrpaSk6MKFCzfcRn5+vvLy8lwagKqN7ACqObe/vP2ngoIC88gjj5j27du7LP/DH/5g1q5da3bt2mUWLVpkGjRoYHr16nXD7UyaNMnr30/RaLSSm6eu+SA7aLTq08qTGzddfDzzzDOmUaNGJjMzs9T1NmzYYCSZffv2ldh/6dIlk5ub62yZmZleP3A0Gu1aq4zig+yg0ap2q7TiIzk52TRs2ND84x//KHPdc+fOGUlm7dq15do2V6zTaL7TPF18kB00WtVv5ckNty44NcZozJgxWrVqlTZu3Kj4+Pgyn7Nz505JUv369d3ZFYAqhOwAUJRbxUdycrKWLFmi1atXKyQkRFlZWZIkh8OhoKAg/fjjj1qyZIl+8YtfKDw8XLt27dK4cePUsWNH3XXXXZXyAgD4PrIDgItync/8J93gFEtaWpoxxphDhw6Zjh07mrCwMGO3202zZs3Miy++6NapW06d0mi+0zz1tcuNtk920GhVr5XnfWv7ZzD4jLy8PDkcDm8PA4CuTYmtW7eut4dRLmQH4BvKkxv8tgsAALAUxQcAALAUxQcAALAUxQcAALAUxQcAALAUxQcAALAUxQcAALAUxQcAALAUxQcAALAUxQcAALAUxQcAALAUxQcAALCUzxUfPvY7d0C15k/vR38aK1CVlee96HPFx9mzZ709BAD/5E/vR38aK1CVlee9aDM+9nGhsLBQR48eVUhIiGw2m/Ly8hQbG6vMzEy/+WlvX8MxrJjqePyMMTp79qxiYmJUo4bPfUYpEdnhWRy/iqtux9Cd3Khp0ZjKrUaNGmrYsGGx5XXr1q0Wf3mViWNYMdXt+DkcDm8PwS1kR+Xg+FVcdTqG5c0N//hIAwAAqgyKDwAAYCmfLz7sdrsmTZoku93u7aH4LY5hxXD8/BN/bxXD8as4juGN+dwFpwAAoGrz+TMfAACgaqH4AAAAlqL4AAAAlqL4AAAAlqL4AAAAlvL54mPWrFlq3LixAgMD1bZtW/31r3/19pB81pdffqkePXooJiZGNptNH3/8sUu/MUYTJ05U/fr1FRQUpC5dumjv3r3eGawPSk1N1b333quQkBDVq1dPPXv21J49e1zWuXTpkpKTkxUeHq7g4GD16dNH2dnZXhoxboTcKD9yo2LIjZvj08XHsmXLNH78eE2aNEk7duxQ69atlZSUpOPHj3t7aD7p/Pnzat26tWbNmlVi/1tvvaV3331X77//vrZu3ao6deooKSlJly5dsnikvmnTpk1KTk5WRkaGPvvsM125ckVdu3bV+fPnneuMGzdOn3zyidLT07Vp0yYdPXpUvXv39uKo8VPkhnvIjYohN26S8WFt2rQxycnJzscFBQUmJibGpKamenFU/kGSWbVqlfNxYWGhiY6ONm+//bZzWU5OjrHb7eZPf/qTF0bo+44fP24kmU2bNhljrh2vWrVqmfT0dOc6f//7340ks2XLFm8NEz9Bbtw8cqPiyI3y8dkzH5cvX9b27dvVpUsX57IaNWqoS5cu2rJlixdH5p/279+vrKwsl+PpcDjUtm1bjucN5ObmSpLCwsIkSdu3b9eVK1dcjmGLFi0UFxfHMfQR5IZnkRvuIzfKx2eLj5MnT6qgoEBRUVEuy6OiopSVleWlUfmv68eM41k+hYWFGjt2rNq3b69WrVpJunYMa9eurdDQUJd1OYa+g9zwLHLDPeRG+dX09gAAX5ScnKzvv/9eX3/9tbeHAsBPkBvl57NnPiIiIhQQEFDsiuDs7GxFR0d7aVT+6/ox43iWbfTo0VqzZo2++OILNWzY0Lk8Ojpaly9fVk5Ojsv6HEPfQW54FrlRfuSGe3y2+Khdu7YSEhK0YcMG57LCwkJt2LBBiYmJXhyZf4qPj1d0dLTL8czLy9PWrVs5nv9kjNHo0aO1atUqff7554qPj3fpT0hIUK1atVyO4Z49e3To0CGOoY8gNzyL3CgbuXGTvH3Fa2mWLl1q7Ha7mTdvntm9e7cZOXKkCQ0NNVlZWd4emk86e/as+e6778x3331nJJlp06aZ7777zhw8eNAYY8wbb7xhQkNDzerVq82uXbvMY489ZuLj483Fixe9PHLf8OyzzxqHw2E2btxojh075mwXLlxwrvPMM8+YuLg48/nnn5tt27aZxMREk5iY6MVR46fIDfeQGxVDbtwcny4+jDFm5syZJi4uztSuXdu0adPGZGRkeHtIPuuLL74wkoq1IUOGGGOuTZv7zW9+Y6KioozdbjcPPfSQ2bNnj3cH7UNKOnaSTFpamnOdixcvmueee87ceuut5pZbbjG9evUyx44d896gUSJyo/zIjYohN26OzRhjrDvPAgAAqjufveYDAABUTRQfAADAUhQfAADAUhQfAADAUhQfAADAUhQfAADAUhQfAADAUhQfAADAUhQfAADAUhQfAADAUhQfAADAUv8PIRfmVda3FhwAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Part C\n",
        "\n",
        "class TheLayerInNN(nn.Linear):\n",
        "    def __init__(self, in_features, out_features, bias=True, device=None, dtype=None):\n",
        "        super().__init__(in_features, out_features, bias, device, dtype)\n",
        "        self.num_epochs = 1000\n",
        "        self.threshold = 2 # it seems that the best value for threshold is 2 by doing experiments.\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #We normalize all x and then do forward pass.\n",
        "        x=x/(x.norm(2,1,keepdim=True)+1e-4)\n",
        "        # We do forward pass, (like HW 2, Python Exercise, Question 1) and use ReLU activation function\n",
        "        # Moreover, we had to add 1 dimension to make the add operator possible between b and xw.T\n",
        "        z=torch.matmul(x, self.weight.T) + torch.unsqueeze(self.bias,(0))\n",
        "        return torch.relu(z)\n",
        "\n",
        "    def train(self,x_positive,x_negative):\n",
        "        opt_function=Adam(self.parameters(),lr=0.03)\n",
        "        #In each epoch, we calculate\n",
        "        for i in range(self.num_epochs):\n",
        "\n",
        "            # To compute the goodness, we need to use power 2 of x_positive and x_negative to compare them\n",
        "            # with the threshold.\n",
        "\n",
        "            # The optimization function is power 2 of the output of the neural.\n",
        "            # Also we use the mean on all the weights to creat a number of every image.\n",
        "            # Thus, for every image, we can compare it with a threshold and decide that what class should it be classified\n",
        "\n",
        "            positive_data=torch.mean(self.forward(x_positive)**2,axis=1)\n",
        "            negative_data=torch.mean(self.forward(x_negative)**2,axis=1)\n",
        "\n",
        "            #ccording to objective function mentioned in the quesion we need to concatenate the two parts\n",
        "            # of the loss, so we have:\n",
        "\n",
        "            loss=torch.log(1+torch.exp(torch.cat([self.threshold-positive_data,negative_data-self.threshold])))\n",
        "            loss=torch.mean(loss)\n",
        "\n",
        "            # we set gradient to zero for calculation a forward gradient according to next lines:\n",
        "            opt_function.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            #We did not use backpropagation, we just update the value of loss by using loss.backward()\n",
        "            opt_function.step()\n",
        "            if i%25== 0:\n",
        "                print(\"Loss after epoch \"+str(i)+\" is :\"+str(loss.item()))\n",
        "        #for hardware issues, we use .detach()\n",
        "        return self.forward(x_positive).detach(), self.forward(x_negative).detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ForwardToForwardNN(torch.nn.Module):\n",
        "    def __init__(self, dims):\n",
        "\n",
        "        super().__init__()\n",
        "        self.layers = []\n",
        "        # if we have L layers, we need to consider L-1 stages\n",
        "        #for calculating weights, so we append all the layers:\n",
        "        L=len(dims)\n",
        "        for d in range(L-1):\n",
        "            self.layers=self.layers+[(TheLayerInNN(dims[d],dims[d+1]).to(device))]\n",
        "\n",
        "\n",
        "    #In all layers, we calculate x_positive and x_negative and pass these arguments through the network.\n",
        "\n",
        "\n",
        "    def train(self, x_positive, x_negative):\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x_positive,x_negative=layer.train(x_positive,x_negative)\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        goodness_per_label = []\n",
        "        for label in range(10):\n",
        "            #We consider all labels from 0 to 9 in MNIST data, so\n",
        "            # we determine x_positive for all these.\n",
        "            x_positive=combined_image(x,label)\n",
        "            goodness=[]\n",
        "            # In all layers of the network, we first, pass the input through network,\n",
        "            # then calculate loss_function( or goodness )\n",
        "\n",
        "            # Note that for all goodnesses, we combination\n",
        "            # the previous value and new value of goodness using \"+\" with the new list.\n",
        "\n",
        "            for layer in self.layers:\n",
        "                x_positive = layer(x_positive)\n",
        "                goodness=goodness+[torch.mean(x_positive*x_positive,axis=1)]\n",
        "\n",
        "            goodness_per_label+=[torch.unsqueeze(sum(goodness),(1))]\n",
        "\n",
        "        #We have 10 classes, so we concatenate features to decide which class has the most probability.\n",
        "        #by the following code:\n",
        "        goodness_per_label=torch.cat(goodness_per_label,1)\n",
        "\n",
        "        #We consider the maximum value among the value that goodness decides as the predicted label.\n",
        "        return goodness_per_label.argmax(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dims=[x.shape[1],256,256]\n",
        "net=ForwardToForwardNN(dims=dims)\n",
        "#net=Net([x.shape[1],2000,2000,2000,2000])# it seems that the proposed architecture in the article is too massive!\n",
        "# so I used a 256*256 hidden layers instead of 2000*2000*2000*2000.\n",
        "\n",
        "net.train(x_positive,x_negative)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENkL55zn63tO",
        "outputId": "4f815a0f-90a6-4558-a567-bf6fe8675df5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after epoch 0 is :1.1267706155776978\n",
            "Loss after epoch 25 is :0.7183191776275635\n",
            "Loss after epoch 50 is :0.7027506232261658\n",
            "Loss after epoch 75 is :0.6971085667610168\n",
            "Loss after epoch 100 is :0.6907996535301208\n",
            "Loss after epoch 125 is :0.6804167032241821\n",
            "Loss after epoch 150 is :0.6635582447052002\n",
            "Loss after epoch 175 is :0.6387032866477966\n",
            "Loss after epoch 200 is :0.6089634895324707\n",
            "Loss after epoch 225 is :0.5794064998626709\n",
            "Loss after epoch 250 is :0.5518003702163696\n",
            "Loss after epoch 275 is :0.5266143083572388\n",
            "Loss after epoch 300 is :0.5039002895355225\n",
            "Loss after epoch 325 is :0.48359233140945435\n",
            "Loss after epoch 350 is :0.4654412865638733\n",
            "Loss after epoch 375 is :0.4493106007575989\n",
            "Loss after epoch 400 is :0.4350229501724243\n",
            "Loss after epoch 425 is :0.4223118722438812\n",
            "Loss after epoch 450 is :0.4109235107898712\n",
            "Loss after epoch 475 is :0.4006335735321045\n",
            "Loss after epoch 500 is :0.3912636637687683\n",
            "Loss after epoch 525 is :0.3826829493045807\n",
            "Loss after epoch 550 is :0.37476202845573425\n",
            "Loss after epoch 575 is :0.3674147427082062\n",
            "Loss after epoch 600 is :0.36058327555656433\n",
            "Loss after epoch 625 is :0.3541930317878723\n",
            "Loss after epoch 650 is :0.3481599986553192\n",
            "Loss after epoch 675 is :0.3424042761325836\n",
            "Loss after epoch 700 is :0.3368820250034332\n",
            "Loss after epoch 725 is :0.33159688115119934\n",
            "Loss after epoch 750 is :0.3265203833580017\n",
            "Loss after epoch 775 is :0.32161590456962585\n",
            "Loss after epoch 800 is :0.31687361001968384\n",
            "Loss after epoch 825 is :0.31228119134902954\n",
            "Loss after epoch 850 is :0.307821661233902\n",
            "Loss after epoch 875 is :0.30349308252334595\n",
            "Loss after epoch 900 is :0.299294650554657\n",
            "Loss after epoch 925 is :0.2952216565608978\n",
            "Loss after epoch 950 is :0.29127237200737\n",
            "Loss after epoch 975 is :0.2874399423599243\n",
            "Loss after epoch 0 is :1.1264210939407349\n",
            "Loss after epoch 25 is :0.5544131398200989\n",
            "Loss after epoch 50 is :0.5298364162445068\n",
            "Loss after epoch 75 is :0.4977395832538605\n",
            "Loss after epoch 100 is :0.46255752444267273\n",
            "Loss after epoch 125 is :0.4318941831588745\n",
            "Loss after epoch 150 is :0.40816792845726013\n",
            "Loss after epoch 175 is :0.3896641433238983\n",
            "Loss after epoch 200 is :0.37420573830604553\n",
            "Loss after epoch 225 is :0.3605630695819855\n",
            "Loss after epoch 250 is :0.3485782742500305\n",
            "Loss after epoch 275 is :0.3381193280220032\n",
            "Loss after epoch 300 is :0.3288458585739136\n",
            "Loss after epoch 325 is :0.32053694128990173\n",
            "Loss after epoch 350 is :0.3130419850349426\n",
            "Loss after epoch 375 is :0.306229829788208\n",
            "Loss after epoch 400 is :0.3000045716762543\n",
            "Loss after epoch 425 is :0.29428529739379883\n",
            "Loss after epoch 450 is :0.28900882601737976\n",
            "Loss after epoch 475 is :0.2841109335422516\n",
            "Loss after epoch 500 is :0.2795460522174835\n",
            "Loss after epoch 525 is :0.27528101205825806\n",
            "Loss after epoch 550 is :0.27129411697387695\n",
            "Loss after epoch 575 is :0.26757073402404785\n",
            "Loss after epoch 600 is :0.2640881836414337\n",
            "Loss after epoch 625 is :0.2608126997947693\n",
            "Loss after epoch 650 is :0.25771600008010864\n",
            "Loss after epoch 675 is :0.2547858953475952\n",
            "Loss after epoch 700 is :0.25202035903930664\n",
            "Loss after epoch 725 is :0.249406635761261\n",
            "Loss after epoch 750 is :0.24692663550376892\n",
            "Loss after epoch 775 is :0.24456872045993805\n",
            "Loss after epoch 800 is :0.24233795702457428\n",
            "Loss after epoch 825 is :0.24022617936134338\n",
            "Loss after epoch 850 is :0.23821866512298584\n",
            "Loss after epoch 875 is :0.23630332946777344\n",
            "Loss after epoch 900 is :0.2344694435596466\n",
            "Loss after epoch 925 is :0.23270925879478455\n",
            "Loss after epoch 950 is :0.23102159798145294\n",
            "Loss after epoch 975 is :0.2294015735387802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### Part D\n",
        "\n",
        "preds=net.predict(x)\n",
        "accuracy_train=torch.sum(100*(preds==y))/len(preds)\n",
        "accuracy_train=accuracy_train.to('cpu')\n",
        "print(\"Train accuracy:\"+str(np.array(accuracy_train))+\"%\")\n",
        "print(\"Train error:\"+str(100-np.array(accuracy_train))+\"%\")\n",
        "x_test,y_test=next(iter(test_loader))\n",
        "x_test,y_test=x_test.to(device),y_test.to(device)\n",
        "x_test=torch.reshape(x_test,(num_test,x_test.shape[2]*x_test.shape[3]))\n",
        "preds=net.predict(x_test)\n",
        "accuracy_test=torch.sum(100*(preds==y_test))/len(preds)\n",
        "accuracy_test=accuracy_test.to('cpu')\n",
        "print(\"Test accuracy:\"+str(np.array(accuracy_test))+\"%\")\n",
        "print(\"Test error:\"+str(100-np.array(accuracy_test))+\"%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DwM3aKVj64SG",
        "outputId": "1e16b4c7-3cb1-4b90-b2db-831196c13fe7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy:91.397995%\n",
            "Train error:8.602005004882812%\n",
            "Test accuracy:91.329994%\n",
            "Test error:8.670005798339844%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsupervised Learning\n",
        "\n",
        "\n",
        "# Part A\n",
        "# For negative images, we have to generate hybrid images, by help of masks.\n",
        "# These masks are generated randomly with the probability of p=0.1 ==> 0.1 and\n",
        "# 1-p = 0.9 ==> 0\n",
        "\n",
        "\n",
        "def combined_image_for_negative(x,masks):\n",
        "    x_new=torch.zeros(x.shape)\n",
        "    for i in range(x_new.shape[0]):\n",
        "        index=np.random.randint(x.shape[0])\n",
        "        x_new[i,:,:]=torch.multiply(masks[i,:,:],x[i,:,:])+torch.multiply(1-masks[i,:,:],x[index,:,:])\n",
        "\n",
        "\n",
        "    return x_new\n",
        "\n",
        "\n",
        "p=0.5\n",
        "values=[1,0]\n",
        "probs=[p,1-p]\n",
        "masks=torch.zeros((x.shape[0], int(np.sqrt(x.shape[1])),int(np.sqrt(x.shape[1]))))\n",
        "mask=torch.zeros(( int(np.sqrt(x.shape[1])),int(np.sqrt(x.shape[1]))))\n",
        "for j in range(mask.shape[0]):\n",
        "   for k in range(mask.shape[1]):\n",
        "    mask[j,k]=random.choices(values,probs)[0]\n",
        "for i in range(num_train):\n",
        "    masks[i,:,:]=mask\n"
      ],
      "metadata": {
        "id": "NBOd-NoD8d10"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Part B\n",
        "x_positive=x\n",
        "x=x.to('cpu')\n",
        "x_image=np.reshape(x,(x.shape[0], int(np.sqrt(x.shape[1])),int(np.sqrt(x.shape[1]))))\n",
        "x_negative=combined_image_for_negative(x_image,masks)\n",
        "x_negative=torch.reshape(x_negative,(num_train,x_negative.shape[1]*x_negative.shape[2]))\n",
        "x_negative=x_negative.to(device)\n",
        "x_positive=x_positive.to(device)\n",
        "x=x.to(device)\n",
        "index_for_img=np.random.randint(num_train)\n",
        "plt.subplot(1,2,1)\n",
        "the_img_pos=torch.reshape(x_positive[index_for_img,:],(28,28))\n",
        "the_img_pos=the_img_pos.to('cpu')\n",
        "the_img_numpy_pos=the_img_pos.numpy()\n",
        "plt.imshow(np.array(255*the_img_numpy_pos,dtype=np.uint8),cmap='gray')\n",
        "plt.title(\"Real Image\")\n",
        "plt.subplot(1,2,2)\n",
        "the_img_neg=torch.reshape(x_negative[index_for_img,:],(28,28))\n",
        "the_img_neg=the_img_neg.to('cpu')\n",
        "the_img_numpy_neg=the_img_neg.numpy()\n",
        "plt.imshow(np.array(255*the_img_numpy_neg,dtype=np.uint8),cmap='gray')\n",
        "plt.title(\"Hybrid Image\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "xCzPaxSq8vEl",
        "outputId": "64597833-6c80-465d-939b-bac0e201ee51"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Hybrid Image')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TheLayerInNN(nn.Linear):\n",
        "    def __init__(self, in_features, out_features, bias=True, device=None, dtype=None):\n",
        "        super().__init__(in_features, out_features, bias, device, dtype)\n",
        "        self.num_epochs = 1000\n",
        "        self.threshold = 2 # it seems that the best value for threshold is 2 by doing experiments.\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #We normalize all x and then do forward pass.\n",
        "        x=x/(x.norm(2,1,keepdim=True)+1e-4)\n",
        "        # We do forward pass, (like HW 2, Python Exercise, Question 1) and use ReLU activation function\n",
        "        # Moreover, we had to add 1 dimension to make the add operator possible between b and xw.T\n",
        "        z=torch.matmul(x, self.weight.T) + torch.unsqueeze(self.bias,(0))\n",
        "        return torch.relu(z)\n",
        "\n",
        "    def train(self,x_positive,x_negative):\n",
        "        opt_function=Adam(self.parameters(),lr=0.03)\n",
        "        #In each epoch, we calculate\n",
        "        for i in range(self.num_epochs):\n",
        "\n",
        "            # To compute the goodness, we need to use power 2 of x_positive and x_negative to compare them\n",
        "            # with the threshold.\n",
        "\n",
        "            # The optimization function is power 2 of the output of the neural.\n",
        "            # Also we use the mean on all the weights to creat a number of every image.\n",
        "            # Thus, for every image, we can compare it with a threshold and decide that what class should it be classified\n",
        "\n",
        "            positive_data=torch.mean(self.forward(x_positive)**2,axis=1)\n",
        "            negative_data=torch.mean(self.forward(x_negative)**2,axis=1)\n",
        "\n",
        "            #ccording to objective function mentioned in the quesion we need to concatenate the two parts\n",
        "            # of the loss, so we have:\n",
        "\n",
        "            loss=torch.log(1+torch.exp(torch.cat([self.threshold-positive_data,negative_data-self.threshold])))\n",
        "            loss=torch.mean(loss)\n",
        "\n",
        "            # we set gradient to zero for calculation a forward gradient according to next lines:\n",
        "            opt_function.zero_grad()\n",
        "            loss.backward()\n",
        "\n",
        "            #We did not use backpropagation, we just update the value of loss by using loss.backward()\n",
        "            opt_function.step()\n",
        "            if i%25== 0:\n",
        "                print(\"Loss after epoch \"+str(i)+\" is :\"+str(loss.item()))\n",
        "        #for hardware issues, we use .detach()\n",
        "        return self.forward(x_positive).detach(), self.forward(x_negative).detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ForwardToForwardNN(torch.nn.Module):\n",
        "    def __init__(self, dims):\n",
        "\n",
        "        super().__init__()\n",
        "        self.layers = []\n",
        "        # if we have L layers, we need to consider L-1 stages\n",
        "        #for calculating weights, so we append all the layers:\n",
        "        L=len(dims)\n",
        "        for d in range(L-1):\n",
        "            self.layers=self.layers+[(TheLayerInNN(dims[d],dims[d+1]).to(device))]\n",
        "\n",
        "\n",
        "    #In all layers, we calculate x_positive and x_negative and pass these arguments through the network.\n",
        "\n",
        "\n",
        "    def train(self, x_positive, x_negative):\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            x_positive,x_negative=layer.train(x_positive,x_negative)\n",
        "\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "        goodness_per_label = []\n",
        "        for label in range(10):\n",
        "            #We consider all labels from 0 to 9 in MNIST data, so\n",
        "            # we determine x_positive for all these.\n",
        "            x_positive=combined_image(x,label)\n",
        "            goodness=[]\n",
        "            # In all layers of the network, we first, pass the input through network,\n",
        "            # then calculate loss_function( or goodness )\n",
        "\n",
        "            # Note that for all goodnesses, we combination\n",
        "            # the previous value and new value of goodness using \"+\" with the new list.\n",
        "\n",
        "            for layer in self.layers:\n",
        "                x_positive = layer(x_positive)\n",
        "                goodness=goodness+[torch.mean(x_positive*x_positive,axis=1)]\n",
        "\n",
        "            goodness_per_label+=[torch.unsqueeze(sum(goodness),(1))]\n",
        "\n",
        "        #We have 10 classes, so we concatenate features to decide which class has the most probability.\n",
        "        #by the following code:\n",
        "        goodness_per_label=torch.cat(goodness_per_label,1)\n",
        "\n",
        "        #We consider the maximum value among the value that goodness decides as the predicted label.\n",
        "        return goodness_per_label.argmax(1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "dims=[x.shape[1],256,256]\n",
        "net=ForwardToForwardNN(dims=dims)\n",
        "#net=Net([x.shape[1],2000,2000,2000,2000])# it seems that the proposed architecture in the article is too massive!\n",
        "# so I used a 256*256 hidden layers instead of 2000*2000*2000*2000.\n",
        "\n",
        "net.train(x_positive,x_negative)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIKoQTXo-Czc",
        "outputId": "43ef52a8-057f-489b-bdc9-daf61c8afa60"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss after epoch 0 is :1.126747727394104\n",
            "Loss after epoch 25 is :0.712084174156189\n",
            "Loss after epoch 50 is :0.6959106922149658\n",
            "Loss after epoch 75 is :0.6687073111534119\n",
            "Loss after epoch 100 is :0.6175317168235779\n",
            "Loss after epoch 125 is :0.5543983578681946\n",
            "Loss after epoch 150 is :0.5010771155357361\n",
            "Loss after epoch 175 is :0.46638020873069763\n",
            "Loss after epoch 200 is :0.43862560391426086\n",
            "Loss after epoch 225 is :0.4152476489543915\n",
            "Loss after epoch 250 is :0.39578667283058167\n",
            "Loss after epoch 275 is :0.3793778717517853\n",
            "Loss after epoch 300 is :0.3652878403663635\n",
            "Loss after epoch 325 is :0.3529853820800781\n",
            "Loss after epoch 350 is :0.3420945107936859\n",
            "Loss after epoch 375 is :0.33233901858329773\n",
            "Loss after epoch 400 is :0.3235168159008026\n",
            "Loss after epoch 425 is :0.31547415256500244\n",
            "Loss after epoch 450 is :0.30809032917022705\n",
            "Loss after epoch 475 is :0.30127009749412537\n",
            "Loss after epoch 500 is :0.2949378490447998\n",
            "Loss after epoch 525 is :0.28903326392173767\n",
            "Loss after epoch 550 is :0.28351113200187683\n",
            "Loss after epoch 575 is :0.27833613753318787\n",
            "Loss after epoch 600 is :0.27348002791404724\n",
            "Loss after epoch 625 is :0.2689152657985687\n",
            "Loss after epoch 650 is :0.26461660861968994\n",
            "Loss after epoch 675 is :0.26056087017059326\n",
            "Loss after epoch 700 is :0.25672680139541626\n",
            "Loss after epoch 725 is :0.25309476256370544\n",
            "Loss after epoch 750 is :0.24964679777622223\n",
            "Loss after epoch 775 is :0.2463662028312683\n",
            "Loss after epoch 800 is :0.24323831498622894\n",
            "Loss after epoch 825 is :0.24025048315525055\n",
            "Loss after epoch 850 is :0.23739171028137207\n",
            "Loss after epoch 875 is :0.23465128242969513\n",
            "Loss after epoch 900 is :0.2320200651884079\n",
            "Loss after epoch 925 is :0.2294897735118866\n",
            "Loss after epoch 950 is :0.22705280780792236\n",
            "Loss after epoch 975 is :0.2247024029493332\n",
            "Loss after epoch 0 is :1.1264363527297974\n",
            "Loss after epoch 25 is :0.5179499983787537\n",
            "Loss after epoch 50 is :0.47064247727394104\n",
            "Loss after epoch 75 is :0.4503295123577118\n",
            "Loss after epoch 100 is :0.43543437123298645\n",
            "Loss after epoch 125 is :0.42335617542266846\n",
            "Loss after epoch 150 is :0.4135759174823761\n",
            "Loss after epoch 175 is :0.4056606888771057\n",
            "Loss after epoch 200 is :0.39924100041389465\n",
            "Loss after epoch 225 is :0.39401233196258545\n",
            "Loss after epoch 250 is :0.38972800970077515\n",
            "Loss after epoch 275 is :0.38618898391723633\n",
            "Loss after epoch 300 is :0.3832293748855591\n",
            "Loss after epoch 325 is :0.38070210814476013\n",
            "Loss after epoch 350 is :0.37846389412879944\n",
            "Loss after epoch 375 is :0.37635186314582825\n",
            "Loss after epoch 400 is :0.37418726086616516\n",
            "Loss after epoch 425 is :0.3718516230583191\n",
            "Loss after epoch 450 is :0.36939263343811035\n",
            "Loss after epoch 475 is :0.36698880791664124\n",
            "Loss after epoch 500 is :0.36477869749069214\n",
            "Loss after epoch 525 is :0.36277052760124207\n",
            "Loss after epoch 550 is :0.36092713475227356\n",
            "Loss after epoch 575 is :0.3592148423194885\n",
            "Loss after epoch 600 is :0.3576008975505829\n",
            "Loss after epoch 625 is :0.3560590147972107\n",
            "Loss after epoch 650 is :0.3545670211315155\n",
            "Loss after epoch 675 is :0.3531072437763214\n",
            "Loss after epoch 700 is :0.3516659736633301\n",
            "Loss after epoch 725 is :0.3502383828163147\n",
            "Loss after epoch 750 is :0.34882593154907227\n",
            "Loss after epoch 775 is :0.3474296033382416\n",
            "Loss after epoch 800 is :0.34605279564857483\n",
            "Loss after epoch 825 is :0.344697505235672\n",
            "Loss after epoch 850 is :0.34336599707603455\n",
            "Loss after epoch 875 is :0.3420621454715729\n",
            "Loss after epoch 900 is :0.34078940749168396\n",
            "Loss after epoch 925 is :0.3395496904850006\n",
            "Loss after epoch 950 is :0.3383431136608124\n",
            "Loss after epoch 975 is :0.3371680676937103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### Part D\n",
        "\n",
        "preds=net.predict(x)\n",
        "accuracy_train=torch.sum(100*(preds==y))/len(preds)\n",
        "accuracy_train=accuracy_train.to('cpu')\n",
        "print(\"Train accuracy:\"+str(np.array(accuracy_train))+\"%\")\n",
        "print(\"Train error:\"+str(100-np.array(accuracy_train))+\"%\")\n",
        "x_test,y_test=next(iter(test_loader))\n",
        "x_test,y_test=x_test.to(device),y_test.to(device)\n",
        "x_test=torch.reshape(x_test,(num_test,x_test.shape[2]*x_test.shape[3]))\n",
        "preds=net.predict(x_test)\n",
        "accuracy_test=torch.sum(100*(preds==y_test))/len(preds)\n",
        "accuracy_test=accuracy_test.to('cpu')\n",
        "print(\"Test accuracy:\"+str(np.array(accuracy_test))+\"%\")\n",
        "print(\"Test error:\"+str(100-np.array(accuracy_test))+\"%\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3R_w5XNAnEx",
        "outputId": "e4cb4643-3697-4e54-a1a4-01148079fa84"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy:10.191999%\n",
            "Train error:89.8080005645752%\n",
            "Test accuracy:10.309999%\n",
            "Test error:89.69000053405762%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}